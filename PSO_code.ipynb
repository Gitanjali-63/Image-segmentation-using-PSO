{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSO-code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNvEKPY2E1RExTDFgfZJcWM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gitanjali-63/Image-segmentation-using-PSO/blob/main/PSO_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gmqWdf_Qa_I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from sklearn import svm\n",
        "from mpl_toolkits.mplot3d import axes3d, Axes3D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv('Brain Tumor (1).csv')"
      ],
      "metadata": {
        "id": "Ty_EJiXJQdlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.plot()"
      ],
      "metadata": {
        "id": "saAxSzISQhaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "tCanqN-YQlNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del data['Image']"
      ],
      "metadata": {
        "id": "JZf6bWz8QnU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizing the data\n",
        "\n",
        "data_n = data.copy()\n",
        "data_n = (data - data.min())/(data.max() - data.min())\n",
        "\n",
        "print(data_n)"
      ],
      "metadata": {
        "id": "unBOfc6DQoAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions=12\n",
        "data_cn=pd.concat([data_n.shift(i) for i in range(0+dimensions+1)],axis=1)\n",
        "print(data_cn)"
      ],
      "metadata": {
        "id": "m68SaY5aQq1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into train, validation and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "x=data_cn.iloc[12:,1:]\n",
        "y=data_cn.iloc[12:,0]\n",
        "\n",
        "x_train,x_val,y_train,y_val=train_test_split(x,y,test_size=0.4,shuffle=False)\n",
        "\n",
        "x_val,x_test,y_val,y_test=train_test_split(x_val,y_val,test_size=0.5,shuffle=False)\n",
        "\n",
        "print(len(y_val))\n",
        "print(len(y_test))\n",
        "print(len(y_train))"
      ],
      "metadata": {
        "id": "Y5JIml-NQuWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PSO \n",
        "from sklearn.model_selection import train_test_split\n",
        "def pso(n_particles, iterations, dimensions, inertia):\n",
        "\n",
        "    # Range of SVR's hyperparameters (Particles' search space)\n",
        "    # C, Epsilon and Gamma\n",
        "    max_c = 1e4\n",
        "    min_c = 1e-3\n",
        "    max_e = 1e-1\n",
        "    min_e = 1e-8\n",
        "    max_g = 1e3\n",
        "    min_g = 1e-3\n",
        "    \n",
        "    # Initializing particles' positions randomly, inside\n",
        "    # the search space\n",
        "    x = np.random.rand(n_particles, 1)*(max_c - min_c) + min_c\n",
        "    y = np.random.rand(n_particles, 1)*(max_e - min_e) + min_e\n",
        "    z = np.random.rand(n_particles, 1)*(max_g - min_g) + min_g\n",
        "\n",
        "    c = np.concatenate((x,y,z), axis=1)\n",
        "\n",
        "    # Initializing particles' parameters\n",
        "    v = np.zeros((n_particles, dimensions))\n",
        "    c1 = 2\n",
        "    c2 = 2\n",
        "    p_best = np.zeros((n_particles, dimensions))\n",
        "    p_best_val = np.zeros(n_particles) + sys.maxsize  \n",
        "    g_best = np.zeros(dimensions)\n",
        "    g_best_val = sys.maxsize\n",
        "\n",
        "    best_iter = np.zeros(iterations)\n",
        "\n",
        "\n",
        "    # Initializing regression variables\n",
        "    p_best_RGS = np.empty((n_particles), dtype = object);\n",
        "    g_best_RGS = sys.maxsize\n",
        "\n",
        "    \n",
        "\n",
        "    # Displaying tridimensional search space\n",
        "    plot(c)\n",
        "\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn import metrics\n",
        "    \n",
        "    for i in range(iterations):\n",
        "\n",
        "        for j in range(n_particles):\n",
        "          # Starting Regression\n",
        "          rgs = svm.SVR(C = c[j][0], epsilon = c[j][1], gamma = c[j][2])\n",
        "          x_train,x_val,y_train,y_val=train_test_split(x,y,test_size=0.4,shuffle=False)\n",
        "          x_val,x_test,y_val,y_test=train_test_split(x_val,y_val,test_size=0.5,shuffle=False)\n",
        "          # Fitting the curve\n",
        "          rgs.fit(x_train,y_train)\n",
        "          y_predict = rgs.predict(x_val)\n",
        "\n",
        "          # Using Mean Squared Error to verify prediction accuracy\n",
        "          mse = mean_squared_error(y_val, y_predict) \n",
        "\n",
        "          # If mse value for that search point, for that particle,\n",
        "          # is less than its personal best point,\n",
        "          # replace personal best\n",
        "          if(mse < p_best_val[j]):   # mse < p_best_val[j]\n",
        "          # The value below represents the current least Mean Squared Error\n",
        "              p_best_val[j] = mse\n",
        "              \n",
        "              p_best_RGS[j] = rgs\n",
        "                           \n",
        "\n",
        "              # The value below represents the current search coordinates for\n",
        "              # the particle's current least Mean Squared Error found\n",
        "              p_best[j] = c[j].copy()\n",
        "              \n",
        "          # Using auxiliar variable to get the index of the\n",
        "          # particle that found the configuration with the \n",
        "          # minimum MSE value\n",
        "          aux = np.argmin(p_best_val)        \n",
        "        \n",
        "          if(p_best_val[aux] < g_best_val):\n",
        "              # Assigning Particle's current best MSE to the Group's best    \n",
        "              g_best_val = p_best_val[aux]\n",
        "\n",
        "              # Assigning Particle's current best configuration to the Group's best\n",
        "              g_best = p_best[aux].copy()\n",
        "\n",
        "              # Group best regressor:\n",
        "              # the combination of C, Epsilon and Gamma\n",
        "              # that computes the best fitting curve\n",
        "              g_best_RGS = p_best_RGS[aux]\n",
        "\n",
        "        \n",
        "          rand1 = np.random.random()\n",
        "          rand2 = np.random.random()\n",
        "\n",
        "          # The variable below influences directly the particle's velocity.\n",
        "          # It can either make it smaller or bigger. \n",
        "          w = inertia\n",
        "\n",
        "          # The equation below represents Particle's velocity, which is\n",
        "          # the rate of change in its position\n",
        "          v[j] = w*v[j] + c1*(p_best[j] - c[j])*rand1 + c2*(g_best - c[j])*rand2\n",
        "\n",
        "          # Change in the Particle's position \n",
        "          c[j] = c[j] + v[j]\n",
        "\n",
        "          # Below is a series of conditions that stop the particles from\n",
        "          # leaving the search space\n",
        "          if(c[j][2] < min_g):\n",
        "            c[j][2] = min_g\n",
        "          if(c[j][2] > max_g):\n",
        "            c[j][2] = max_g\n",
        "          if(c[j][1] < min_e):\n",
        "            c[j][1] = min_e\n",
        "          if(c[j][1] > max_e):\n",
        "            c[j][1] = max_e\n",
        "          if(c[j][0] < min_c):\n",
        "            c[j][0] = min_c\n",
        "          if(c[j][0] > max_c):\n",
        "            c[j][0] = max_c\n",
        "            \n",
        "     \n",
        "        # The variable below represents the least Mean Squared Error\n",
        "        # of the current iteration\n",
        "        best_iter[i] = g_best_val\n",
        "                \n",
        "        print('Best value iteration # %d = %f\\n'%(i, g_best_val))\n",
        "\n",
        "    # Coordinates found after all the iterations\n",
        "    print('Group Best configuration found: ')\n",
        "    print(g_best)\n",
        "    print('\\n')\n",
        "    print('Best Regressor:\\n')\n",
        "    print(g_best_RGS)\n",
        "    print('\\n')\n",
        "    # Displaying the MSE value variation throughout the iterations\n",
        "    t = range(iterations)\n",
        "    plt.plot(t, best_iter, label='Fitness Value')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Displaying Particles' final configuration\n",
        "    plot(c)\n",
        "\n",
        "    # Making the prediction with the best configuration of C, Epsilon and\n",
        "    # Gamma found by the particles\n",
        "    x_val,x_test,y_val,y_test=train_test_split(x_val,y_val,test_size=0.5,shuffle=False)\n",
        "\n",
        "    predict_test = g_best_RGS.predict(x_test) \n",
        "    # Displaying actual values and predicted values for\n",
        "    # Group's best configuration found overall\n",
        "    print(color.BOLD + 'Predictions with the Population Best Value found:\\n' + color.END)\n",
        "    evaluate(predict_test)  "
      ],
      "metadata": {
        "id": "9R73xN6YQxY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class color:\n",
        "   PURPLE = '\\033[95m'\n",
        "   CYAN = '\\033[96m'\n",
        "   DARKCYAN = '\\033[36m'\n",
        "   BLUE = '\\033[94m'\n",
        "   GREEN = '\\033[92m'\n",
        "   YELLOW = '\\033[93m'\n",
        "   RED = '\\033[91m'\n",
        "   BOLD = '\\033[1m'\n",
        "   UNDERLINE = '\\033[4m'\n",
        "   END = '\\033[0m'"
      ],
      "metadata": {
        "id": "cXcjyjBURBMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that displays tridimensional plot\n",
        "def plot(some_list):\n",
        " \n",
        "  ax = Axes3D(plt.figure())\n",
        "  ax.scatter3D(some_list[:,0], some_list[:,1], some_list[:,2], color = 'r')\n",
        "  ax.set_xlabel('$C$', fontsize = 20)\n",
        "  ax.set_ylabel('$\\epsilon$', fontsize = 25)\n",
        "  ax.zaxis.set_rotate_label(False) \n",
        "  ax.set_zlabel('$\\gamma$', fontsize=30, rotation = 0)\n",
        "  ax.zaxis._axinfo['label']['space_factor'] = 1.0\n",
        "  plt.show()\n",
        "\n",
        "  print('\\n')\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "J0baXcyFRFAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(predictions):\n",
        "\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    import statistics as st\n",
        "\n",
        "    predict_test = predictions\n",
        "\n",
        "    # To un-normalize the data:\n",
        "    # Multiply the values by\n",
        "    # data.to_numpy().max()\n",
        "\n",
        "    plt.plot(range(len(y_test)), y_test, label='Real')\n",
        "    plt.plot(range(len(predict_test)), predict_test, label='Predicted')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    mse = mean_squared_error(y_test, predict_test)\n",
        "    print('\\n')\n",
        "    print('\\n')\n",
        "    print('Mean Squared Error for the Test Set:\\t %f' %mse)\n",
        "    print('\\n')\n",
        "    print('\\n')\n",
        "    print('Predictions Average:\\t %f' %((predict_test.sum()/len(predict_test))))\n",
        "    print('\\n')\n",
        "    print('\\n')\n",
        "    print('Predictions Median:\\t %f' %(st.median(predict_test)))\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "FKMS6ChBRID0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameter of PSO\n",
        "pso(50, 100, 3, 1)"
      ],
      "metadata": {
        "id": "wgKOcWhGRVcU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}